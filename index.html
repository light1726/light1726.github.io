---
layout: page
title: Hui Lu (卢辉)
subtitle: Ph.D. Student at CUHK
use-site-title: true
---



[Last update: 2022/02/10]
<!-- <h3>Short Bio</h3> -->
<p> Hui Lu is now a Ph.D. student at the Chinese University of Hong Kong, supervised by <a herf="https://www.se.cuhk.edu.hk/people/academic-staff/prof-meng-mei-ling-helen/">Prof. Helen Meng</a>. </p>
<p> Hui Lu received his M.Eng degree from Tsinghua University in 2020, supervised by Prof. Zhiyong Wu. Before that, he obtained his B.Eng. degree in Communication Engineering from Tongji University in 2017.</p>
<p>His research interests lie in unsupervised learning of disentangled speech representation and personalized speech generation.</p>

[<a href="https://scholar.google.com/citations?user=NtMHjJAAAAAJ&hl=en">Google Scholar</a>][<a href="https://github.com/light1726">Github</a>]


<h3>Selected Publications</h3>

<h4>Journal Papers</h4>

<li>
    <a target="_blank" href="http://www1.se.cuhk.edu.hk/~hccl/publications/pub/xixin_09328288%20(1).pdf">Exemplar-Based Emotive Speech Synthesis</a><br>
    Xixin Wu, Yuewen Cao, <b>Hui Lu</b>, Songxiang Liu, Shiyin Kang, Zhiyong Wu, Xunying Liu, Helen Meng<br>
    <em>Accepted by IEEE/ACM Transactions on Audio Speech and Language Processing, 2021</em><br>  
</li>

<li>
    <a target="_blank" href="http://www1.se.cuhk.edu.hk/~hccl/publications/pub/xixin_09328288%20(1).pdf">Speech Emotion Recognition using Sequential Capsule Networks</a><br>
    Xixin Wu, Yuewen Cao, <b>Hui Lu</b>, Songxiang Liu, Disong Wang, Zhiyong Wu, Xunying Liu, Helen Meng<br>
    <em>Accepted by IEEE/ACM Transactions on Audio Speech and Language Processing, 2021</em><br>  
</li>

<h4>Conference Papers</h4>


<li>
    <a target="_blank" href="https://www1.se.cuhk.edu.hk/~hccl/publications/pub/3%20lu21d_interspeech.pdf">VAENAR-TTS: Variational Auto-Encoder based Non-AutoRegressive Text-to-Speech Synthesis</a>,
    <a target="_blank" href="https://light1726.github.io/vaenar-tts/">[demo]</a><a target="_blank" href="https://github.com/thuhcsi/VAENAR-TTS">[code]</a><br>
    <b>Hui Lu</b>, Zhiyong Wu, Xixin Wu, Xu Li, Shiyin Kang, Xunying Liu, Helen Meng<br>
    <em>in Interspeech 2021</em><br>  
</li>

<li>
    <a target="_blank" href="https://www1.se.cuhk.edu.hk/~hccl/publications/pub/201909_INTERSPEECH_HuiLU.pdf">One-Shot Voice Conversion with Global Speaker Embeddings</a>,
    <a target="_blank" href="https://daidongyang.github.io/vc-eval/">[demo]</a><br>
    <b>Hui Lu</b>, Zhiyong Wu, Dongyang Dai, Runnan Li, Shiyin Kang, Jia Jia, Helen Meng<br>
    <em>in Interspeech 2019.<br>  
</li>


<li>
    <a target="_blank" href="https://www1.se.cuhk.edu.hk/~hccl/publications/pub/3%2008682938.pdf">A Compact Framework for Voice Conversion Using Wavenet Conditioned on Phonetic Posteriorgrams</a>,
    <a target="_blank" href="https://light1726.github.io/voice_conversion_demo/">[demo]</a><br>
    <b>Hui Lu</b>, Zhiyong Wu, Runnan Li, Shiyin Kang, Jia Jia, Helen Meng<br>
    <em>in ICASSP 2019</em><br>  
</li>


<li>
    <a target="_blank" href="https://arxiv.org/pdf/2203.01080.pdf">A Multi-Scale Time-Frequency Spectrogram Discriminator for GAN-based Non-Autoregressive TTS</a>,
	<a target="_blank" href="https://hhguo.github.io/DemoUGANTTS/">[demo]</a><br>
    Haohan Guo, <b>Hui Lu</b>, Xixin Wu, Helen Meng<br>
    <em>Submitted to Interspeech 2022</em><br>  
</li>

<li>
    <a target="_blank" href="https://arxiv.org/pdf/1910.08716.pdf">Channel-wise Gated Res2Net: Towards Robust Detection of Synthetic Speech Attacks</a>,<br>
    Xu Li, Xixin Wu, <b>Hui Lu</b>, Xunying Liu, Helen Meng<br>
    <em>in Interspeech 2021</em><br>  
</li>


<br><br>
<h4>Contact info</h4>
E-mail: luhui@se.cuhk.edu.hk