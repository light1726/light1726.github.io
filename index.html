---
layout: page
title: Hui Lu (卢辉)
subtitle: Ph.D. Student at CUHK
use-site-title: true
---



<!-- <h3>Short Bio</h3> -->
<p> Hui Lu is now a 3rd-year Ph.D. student at the Chinese University of Hong Kong, supervised by <a herf="https://www.se.cuhk.edu.hk/people/academic-staff/prof-meng-mei-ling-helen/">Prof. Helen Meng</a>. </p>
<p> Hui Lu received his M.Eng degree from Tsinghua University in 2020, supervised by <a herf="https://thuhcsi.github.io/zywu.html">Prof. Zhiyong Wu</a>. Before that, he obtained his B.Eng. degree in Communication Engineering from Tongji University in 2017.</p>
<p>His research interests lie in unsupervised learning of disentangled speech representation and personalized speech generation.</p>

[<a href="https://scholar.google.com/citations?user=NtMHjJAAAAAJ&hl=en">Google Scholar</a>][<a href="https://github.com/light1726">Github</a>]


<h3>Selected Publications</h3>

<h4>Journal Papers</h4>

<li>
    <a target="_blank" href="http://www1.se.cuhk.edu.hk/~hccl/publications/pub/xixin_09328288%20(1).pdf">Exemplar-Based Emotive Speech Synthesis</a><br>
    Xixin Wu, Yuewen Cao, <b>Hui Lu</b>, Songxiang Liu, Shiyin Kang, Zhiyong Wu, Xunying Liu, Helen Meng<br>
    <em>Accepted by IEEE/ACM Transactions on Audio Speech and Language Processing, 2021</em><br>  
</li>

<li>
    <a target="_blank" href="http://www1.se.cuhk.edu.hk/~hccl/publications/pub/xixin_09328288%20(1).pdf">Speech Emotion Recognition using Sequential Capsule Networks</a><br>
    Xixin Wu, Yuewen Cao, <b>Hui Lu</b>, Songxiang Liu, Disong Wang, Zhiyong Wu, Xunying Liu, Helen Meng<br>
    <em>Accepted by IEEE/ACM Transactions on Audio Speech and Language Processing, 2021</em><br>  
</li>

<h4>Conference Papers</h4>

<li>
    <a target="_blank" href="https://www1.se.cuhk.edu.hk/~hccl/publications/pub/2023%20SLT2022-Beta_VAE_based_one_shot_cross_lingual_VC.pdf">Disentangled Speech Representation Learning for One-Shot Cross-Lingual Voice Conversion Using ß-VAE</a>,
    <a target="_blank" href="https://beta-vaevc.github.io/">[demo]</a><a target="_blank" href="https://github.com/light1726/BetaVAE_VC">[code]</a><br>
    <b>Hui Lu</b>, Disong Wang, Xixin Wu, Zhiyong Wu, Xunying Liu, Helen Meng<br>
    <em>in SLT 2022</em><br>  
</li>

<li>
    <a target="_blank" href="https://www1.se.cuhk.edu.hk/~hccl/publications/pub/3%20lu21d_interspeech.pdf">VAENAR-TTS: Variational Auto-Encoder based Non-AutoRegressive Text-to-Speech Synthesis</a>,
    <a target="_blank" href="https://light1726.github.io/vaenar-tts/">[demo]</a><a target="_blank" href="https://github.com/thuhcsi/VAENAR-TTS">[code]</a><br>
    <b>Hui Lu</b>, Zhiyong Wu, Xixin Wu, Xu Li, Shiyin Kang, Xunying Liu, Helen Meng<br>
    <em>in Interspeech 2021</em><br>  
</li>

<li>
    <a target="_blank" href="https://www1.se.cuhk.edu.hk/~hccl/publications/pub/201909_INTERSPEECH_HuiLU.pdf">One-Shot Voice Conversion with Global Speaker Embeddings</a>,
    <a target="_blank" href="https://daidongyang.github.io/vc-eval/">[demo]</a><br>
    <b>Hui Lu</b>, Zhiyong Wu, Dongyang Dai, Runnan Li, Shiyin Kang, Jia Jia, Helen Meng<br>
    <em>in Interspeech 2019.<br>  
</li>


<li>
    <a target="_blank" href="https://www1.se.cuhk.edu.hk/~hccl/publications/pub/3%2008682938.pdf">A Compact Framework for Voice Conversion Using Wavenet Conditioned on Phonetic Posteriorgrams</a>,
    <a target="_blank" href="https://light1726.github.io/voice_conversion_demo/">[demo]</a><br>
    <b>Hui Lu</b>, Zhiyong Wu, Runnan Li, Shiyin Kang, Jia Jia, Helen Meng<br>
    <em>in ICASSP 2019</em><br>  
</li>


<li>
    <a target="_blank" href="https://arxiv.org/pdf/2203.01080.pdf">A Multi-Scale Time-Frequency Spectrogram Discriminator for GAN-based Non-Autoregressive TTS</a>,
	<a target="_blank" href="https://hhguo.github.io/DemoUGANTTS/">[demo]</a><br>
    Haohan Guo, <b>Hui Lu</b>, Xixin Wu, Helen Meng<br>
    <em>Submitted to Interspeech 2022</em><br>  
</li>

<li>
    <a target="_blank" href="https://arxiv.org/pdf/1910.08716.pdf">Channel-wise Gated Res2Net: Towards Robust Detection of Synthetic Speech Attacks</a>,<br>
    Xu Li, Xixin Wu, <b>Hui Lu</b>, Xunying Liu, Helen Meng<br>
    <em>in Interspeech 2021</em><br>  
</li>


<br><br>
<h4>Contact info</h4>
E-mail: luhui@se.cuhk.edu.hk