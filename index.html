---
layout: page
title: Hui Lu (卢辉)
subtitle: Ph.D. Student at CUHK
use-site-title: true
---



<!-- <h3>Short Bio</h3> -->
<p> Hui Lu is now a 4th-year Ph.D. student at the Chinese University of Hong Kong, supervised by <a target="_blank" href="https://www.se.cuhk.edu.hk/people/academic-staff/prof-meng-mei-ling-helen/">Prof. Helen Meng</a>. </p>
<p> Hui Lu received his M.Eng degree in Computer Technology from Tsinghua University in 2020, supervised by <a target="_blank"  href="https://thuhcsi.github.io/zywu.html">Prof. Zhiyong Wu</a>. Before that, he obtained his B.Eng. degree in Communication Engineering from Tongji University in 2017.</p>
<p>His research interests lie in unsupervised learning of disentangled speech representation and personalized speech generation.</p>

[<a href="https://scholar.google.com/citations?user=NtMHjJAAAAAJ&hl=en">Google Scholar</a>][<a href="https://github.com/light1726">Github</a>]


<h3>Selected Publications</h3>

<h4>Journal Papers</h4>

<li>
    <a target="_blank" href="https://www1.se.cuhk.edu.hk/~hccl/publications/pub/Hiformer_Sequence_Modeling_Networks_with_Hierarchical_Attention_Mechanisms.pdf">Hiformer: Sequence Modeling Networks with Hierarchical Attention Mechanisms</a><br>
    Xixin Wu, <b>Hui Lu</b>, Kun Li, Zhiyong Wu, Xunying Liu, Helen Meng<br>
    <em>In IEEE/ACM Transactions on Audio Speech and Language Processing, 2023</em><br>  
</li>

<li>
    <a target="_blank" href="http://www1.se.cuhk.edu.hk/~hccl/publications/pub/xixin_09328288%20(1).pdf">Exemplar-Based Emotive Speech Synthesis</a><br>
    Xixin Wu, Yuewen Cao, <b>Hui Lu</b>, Songxiang Liu, Shiyin Kang, Zhiyong Wu, Xunying Liu, Helen Meng<br>
    <em>In IEEE/ACM Transactions on Audio Speech and Language Processing, 2021</em><br>  
</li>

<li>
    <a target="_blank" href="http://www1.se.cuhk.edu.hk/~hccl/publications/pub/xixin_09328288%20(1).pdf">Speech Emotion Recognition using Sequential Capsule Networks</a><br>
    Xixin Wu, Yuewen Cao, <b>Hui Lu</b>, Songxiang Liu, Disong Wang, Zhiyong Wu, Xunying Liu, Helen Meng<br>
    <em>In IEEE/ACM Transactions on Audio Speech and Language Processing, 2021</em><br>  
</li>

<h4>Conference Papers</h4>
<li>
    <a target="_blank" href="https://www1.se.cuhk.edu.hk/~hccl/publications/pub/mmfp3442-lu-CC-BY.pdf">SpeechTripleNet: End-to-End Disentangled Speech Representation Learning for Content, Timbre and Prosody</a>,
    <a target="_blank" href="https://speechtriplenet.github.io/">[demo]</a><a target="_blank" href="git@github.com:light1726/SpeechTripleNet.git">[code]</a><br>
    <b>Hui Lu</b>, Xixin Wu, Zhiyong Wu, and Helen Meng.<br>
    <em>In ACMMM 2023</em><br>  
</li>

<li>
    <a target="_blank" href="https://www1.se.cuhk.edu.hk/~hccl/publications/pub/2023%20SLT2022-Beta_VAE_based_one_shot_cross_lingual_VC.pdf">Disentangled Speech Representation Learning for One-Shot Cross-Lingual Voice Conversion Using ß-VAE</a>,
    <a target="_blank" href="https://beta-vaevc.github.io/">[demo]</a><a target="_blank" href="https://github.com/light1726/BetaVAE_VC">[code]</a><br>
    <b>Hui Lu</b>, Disong Wang, Xixin Wu, Zhiyong Wu, Xunying Liu, Helen Meng.<br>
    <em>In SLT 2022</em><br>  
</li>

<li>
    <a target="_blank" href="https://www1.se.cuhk.edu.hk/~hccl/publications/pub/3%20lu21d_interspeech.pdf">VAENAR-TTS: Variational Auto-Encoder based Non-AutoRegressive Text-to-Speech Synthesis</a>,
    <a target="_blank" href="https://light1726.github.io/vaenar-tts/">[demo]</a><a target="_blank" href="https://github.com/thuhcsi/VAENAR-TTS">[code]</a><br>
    <b>Hui Lu</b>, Zhiyong Wu, Xixin Wu, Xu Li, Shiyin Kang, Xunying Liu, Helen Meng<br>
    <em>In Interspeech 2021</em><br>  
</li>

<li>
    <a target="_blank" href="https://www1.se.cuhk.edu.hk/~hccl/publications/pub/201909_INTERSPEECH_HuiLU.pdf">One-Shot Voice Conversion with Global Speaker Embeddings</a>,
    <a target="_blank" href="https://daidongyang.github.io/vc-eval/">[demo]</a><br>
    <b>Hui Lu</b>, Zhiyong Wu, Dongyang Dai, Runnan Li, Shiyin Kang, Jia Jia, Helen Meng<br>
    <em>In Interspeech 2019.<br>  
</li>


<li>
    <a target="_blank" href="https://www1.se.cuhk.edu.hk/~hccl/publications/pub/3%2008682938.pdf">A Compact Framework for Voice Conversion Using Wavenet Conditioned on Phonetic Posteriorgrams</a>,
    <a target="_blank" href="https://light1726.github.io/voice_conversion_demo/">[demo]</a><br>
    <b>Hui Lu</b>, Zhiyong Wu, Runnan Li, Shiyin Kang, Jia Jia, Helen Meng<br>
    <em>In ICASSP 2019</em><br>  
</li>

<br><br>
<h4>Contact info</h4>
E-mail: luhui@se.cuhk.edu.hk